{
  "personal_information": {
    "name": "Amey Sadanand Bhilegaonkar",
    "phone": "480-616-3980",
    "email": "ameybhilegaonkar3@gmail.com",
    "github": "github.com/ameygoes",
    "linkedin": "linkedin.com/in/amey-bhilegaonkar"
  },
  "work_experience": [
    {
      "company": "BigCommerce",
      "location": "Austin, Texas",
      "position": "Data Science Intern",
      "start_date": "June 2023",
      "end_date": "August 2023",
      "description": "Designed and managed a large-scale Snowflake data retrieval pipeline for efficient data warehousing. Implemented logistic regression and predictive models, improving customer retention prediction accuracy by 12%. Collaborated with data infrastructure teams to ensure data availability and resolve data-related issues. Leveraged advanced data-mining techniques to process and analyze millions of data points, extracting critical features for search indexing and ranking."
    },
    {
      "company": "Publicis Sapient",
      "location": "Bangalore, India",
      "position": "Data Engineer - II",
      "start_date": "June 2019",
      "end_date": "July 2022",
      "description": "Engineered complex ETL pipelines using Apache Spark, optimizing data extraction, transformation, and loading from diverse sources, such as Redshift, S3, Kinesis Streams, and Kafka. Utilized distributed computing frameworks such as Apache Spark to manage large-scale data processing tasks, enhancing performance and resource utilization by 15%. Independently designed and built database tools and scripts to simplify and automate reduced operation toil by 15%. Improved database performance by optimizing queries and tuning indexes, resulting in a 20% reduction in query execution. Revamped and maintained real-time data streaming solutions with Apache Spark and GCP Cloud Run in large-scale infrastructure markets with over 30 million daily customer transactions, resulting in a 15% revenue increase. Utilized AWS Lambda, EC2, and SNS for scheduled data transformations, cutting pipeline run-time by 2 hours weekly."
    }
  ],
  "projects": [
    {
      "name": "Search Engine for All file types",
      "description": "Opportunity Hackathon - Meta Sponsored",
      "responsibilities": "Spearheaded Elasticsearch implementation for blazing-fast search responses, with millisecond response times. Converted and stored every file type data as vector embeddings, ensuring low-latency search capabilities. Led Python FAST API development, providing efficient data access and retrieval. Used Machine Learning techniques such as BERT, OCR, ResNet50, and Image Captioning to parse Image features. Collaborated effectively with team members, optimizing task distribution for streamlined project completion."
    },
    {
      "name": "Scalable Data Processing Pipeline",
      "description": "Neo4J, Docker, Kafka and Minikube",
      "responsibilities": "Designed and implemented a highly scalable and available data processing pipeline using Kubernetes, Kafka, Docker, Neo4j. Orchestrated the setup of Kafka and Apache Zookeeper using Minikube, a lightweight Kubernetes implementation. Streamlined data ingestion and processing into Neo4j, applying PageRank and BFS for graph-based data exploration."
    },
    {
      "name": "Email Automation Marketing Tool",
      "description": "",
      "responsibilities": "Initiated and completed the development of a robust email automation project, streamlining job application outreach and networking efforts with individuals of similar interests. Employed RESTful API integration to acquire and manage a comprehensive contact database from CRM tools, demonstrating prowess in full-stack development and API design."
    },
    {
      "name": "Speech Emotion Detection",
      "description": "",
      "responsibilities": "Researched and optimized existing emotion detection approaches by combining CNN and LSTM networks. Discovered emotion-affecting attributes in voice by analyzing audio signal features (MFCC, ZCR, Pitch, Chroma)."
    }
  ],
  "education": [
    {
      "university": "Arizona State University",
      "location": "Tempe, USA",
      "degree": "Masters of Science in Computer Science",
      "start_date": "August 2022",
      "end_date": "May 2024",
      "gpa": "4/4"
    },
    {
      "university": "Pune Institute of Computer Technology",
      "location": "Pune, India",
      "degree": "Bachelors of Engineering in Electronics and Telecommunications",
      "start_date": "July 2015",
      "end_date": "May 2019",
      "gpa": "8.78/10"
    }
  ],
  "skills": [
    "Python",
    "Unix / Linux Scripting",
    "SQL",
    "GCP",
    "AWS",
    "Big Query",
    "Cassandra",
    "SnowFlake",
    "Airflow",
    "Spark",
    "Kafka",
    "Pandas",
    "Tableau",
    "D3.js",
    "CI/CD",
    "Git",
    "Jenkins",
    "Docker",
    "Kubernetes"
  ],
  "certifications": [
    "Certified Google Cloud Platform Associate Cloud Engineer"
  ]
}